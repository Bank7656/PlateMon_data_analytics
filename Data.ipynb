{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5a2bf1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Using matplotlib backend: module://matplotlib_inline.backend_inline\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "from src.plot import plot_single_bath, plot_all_params, save_individual_run, save_bath, plot_conductivity_fft\n",
    "from src.load_data import load_sheet, clean_sheet_with_label\n",
    "\n",
    "%load_ext autoreload\n",
    "%matplotlib\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80fcd1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kittyoomm\\Desktop\\Work@MTEC\\PlateMon_data_analytics\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce49d653",
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_df, sheet1 = load_sheet(\"Electroplate Experiments Data JUN_JUL\", \"vary_internal_table\")\n",
    "internal_df = clean_sheet_with_label(internal_df)\n",
    "# two_side_plate, sheet2 = load_sheet(\"Electroplate Experiments Data JUN_JUL\", \"2 side Experimental Result\")\n",
    "# two_side_plate = clean_sheet_with_label(two_side_plate)\n",
    "august_df, sheet3 = load_sheet(\"Electroplating Experiments Data August\", \"Sheet1\")\n",
    "august_df = clean_sheet_with_label(august_df)\n",
    "september_df, sheet4 = load_sheet(\"Electroplating Experiments Data September\", \"Sheet1\")\n",
    "september_df =clean_sheet_with_label(september_df)\n",
    "\n",
    "internal_df[internal_df['bath_id']=='Bath_3']\n",
    "combined_df = pd.concat([internal_df, august_df, september_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f782cb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly C type: ['C3']\n",
      "Anomaly P type: ['N']\n",
      "Anomaly T type: ['N']\n",
      "Anomaly V type: ['N']\n"
     ]
    }
   ],
   "source": [
    "jul_22_3 = combined_df[combined_df['run_id']=='JUL_22_3'].copy()\n",
    "print(f'Anomaly C type: {jul_22_3['Anomaly C'].unique()}')\n",
    "print(f'Anomaly P type: {jul_22_3['Anomaly P'].unique()}')\n",
    "print(f'Anomaly T type: {jul_22_3['Anomaly T'].unique()}')\n",
    "print(f'Anomaly V type: {jul_22_3['Anomaly V'].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2683d3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "SENSOR_FEATURES = [\"conductivity\", \"temperature\", \"pH\",\t\"voltage\"]\n",
    "TRAIN_RUNS = ['JUL_22_1','JUL_22_2', 'JUL_22_3', 'JUL_22_4', 'JUL_22_5', 'JUL_22_6','JUL_22_7', 'JUL_22_8', 'JUL_22_9', \n",
    "\t\t\t  'JUL_23_1', 'JUL_23_2', 'JUL_23_3', 'JUL_23_4', 'JUL_23_5']\n",
    "TEST_RUNS = ['JUL_24_1', 'JUL_24_2',\n",
    "       'JUL_24_3', 'JUL_24_4', 'JUL_24_5', 'JUL_24_6', 'JUL_24_7',\n",
    "       'JUL_24_8', 'JUL_24_9', 'JUL_24_10']\n",
    "\n",
    "#NORMAL_RUNS = ['JUL_22_4', 'JUL_22_5', 'JUL_22_7']\n",
    "#NORMAL_CONDUCTIVITY_RUNS = ['JUL_22_1','JUL_22_2', 'JUL_22_4', 'JUL_22_5', 'JUL_22_7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "097a8d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to separate normal and anomalous data based on specified anomaly label\n",
    "def get_noramal_data(df: pd.DataFrame, runs: list, parameter: str) -> pd.DataFrame:\n",
    "    NORMAL_RUNS = []\n",
    "    VALID_RUNS = []\n",
    "    for run in runs:\n",
    "        checked_df = df[df['run_id'] == run]\n",
    "    \n",
    "        if (checked_df[parameter].unique() == ['N']).all():# and (df['Anomaly P'].unique() == ['N']).all() and (df['Anomaly T'].unique() == ['N']).all() and (df['Anomaly V'].unique() == ['N']).all():\n",
    "            if run in NORMAL_RUNS:\n",
    "                continue\n",
    "            else:\n",
    "                NORMAL_RUNS.append(run)\n",
    "        else:\n",
    "            VALID_RUNS.append(run)\n",
    "\n",
    "    print(\"Normal runs:\", NORMAL_RUNS)\n",
    "    print(\"Valid runs:\", VALID_RUNS)\n",
    "    \n",
    "    train_df = df[df['run_id'].isin(NORMAL_RUNS)].copy()\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    train_df['index'] = train_df.index\n",
    "    \n",
    "    valid_df = df[df['run_id'].isin(VALID_RUNS)].copy()\n",
    "    valid_df = valid_df.reset_index(drop=True)\n",
    "    valid_df['index'] = valid_df.index\n",
    "    \n",
    "    return train_df, valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cda88e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal runs: ['JUL_22_1', 'JUL_22_2', 'JUL_22_4', 'JUL_22_5', 'JUL_22_7']\n",
      "Valid runs: ['JUL_22_3', 'JUL_22_6', 'JUL_22_8', 'JUL_22_9', 'JUL_23_1', 'JUL_23_2', 'JUL_23_3', 'JUL_23_4', 'JUL_23_5']\n"
     ]
    }
   ],
   "source": [
    "# Seperating normal and anomalous data based on 'Anomaly C' label --> used as train and validation datasets, respectively\n",
    "train_c_df, valid_c_df = get_noramal_data(combined_df, TRAIN_RUNS, 'Anomaly C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a62d8ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------df------------------------\n",
      "Anomaly C type: ['' 'N' 'C3' 'C1' 'C2' None]\n",
      "Anomaly P type: ['' 'N' None]\n",
      "Anomaly T type: ['' 'N' None]\n",
      "Anomaly V type: ['' 'N' 'V1' 'V2' None]\n",
      "-------------------Train df---------------------\n",
      "Anomaly C type: ['N']\n",
      "Anomaly P type: ['N']\n",
      "Anomaly T type: ['N']\n",
      "Anomaly V type: ['N' 'V1' 'V2']\n",
      "-----------------Validation df------------------\n",
      "Anomaly C type: ['C3' 'N' 'C1' 'C2']\n",
      "Anomaly P type: ['N']\n",
      "Anomaly T type: ['N']\n",
      "Anomaly V type: ['N' 'V1' 'V2']\n"
     ]
    }
   ],
   "source": [
    "# Checking anomaly label types in each dataset\n",
    "print(f'----------------------df------------------------')\n",
    "print(f'Anomaly C type: {combined_df['Anomaly C'].unique()}')\n",
    "print(f'Anomaly P type: {combined_df['Anomaly P'].unique()}')\n",
    "print(f'Anomaly T type: {combined_df['Anomaly T'].unique()}')\n",
    "print(f'Anomaly V type: {combined_df['Anomaly V'].unique()}')\n",
    "print(f'-------------------Train df---------------------')\n",
    "print(f'Anomaly C type: {train_c_df['Anomaly C'].unique()}')\n",
    "print(f'Anomaly P type: {train_c_df['Anomaly P'].unique()}')\n",
    "print(f'Anomaly T type: {train_c_df['Anomaly T'].unique()}')\n",
    "print(f'Anomaly V type: {train_c_df['Anomaly V'].unique()}')\n",
    "print(f'-----------------Validation df------------------')\n",
    "print(f'Anomaly C type: {valid_c_df['Anomaly C'].unique()}')\n",
    "print(f'Anomaly P type: {valid_c_df['Anomaly P'].unique()}')\n",
    "print(f'Anomaly T type: {valid_c_df['Anomaly T'].unique()}')\n",
    "print(f'Anomaly V type: {valid_c_df['Anomaly V'].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d3ee09c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving processed datasets to Excel files\n",
    "train_c_df = train_c_df[['run_id', 'conductivity', 'index', 'timestamp']]\n",
    "train_c_df.to_excel('Datasets/train_c_data.xlsx', index=False)\n",
    "\n",
    "valid_c_df['anomaly_label'] = valid_c_df['Anomaly C'].apply(lambda x: 0 if x == 'N' else 1) # Creating binary anomaly label\n",
    "valid_c_df = valid_c_df[['run_id', 'conductivity', 'index', 'timestamp', 'anomaly_label']]\n",
    "valid_c_df.to_excel('Datasets/valid_c_data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dc8a8c",
   "metadata": {},
   "source": [
    "---------- ^^^ ---------- Used Code ---------- ^^^ ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b517bbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your time column is named 'timestamp' and is not yet the index\n",
    "filtered_df['timestamp'] = pd.to_datetime(filtered_df['timestamp']) # Convert to datetime objects\n",
    "filtered_df = filtered_df.set_index('timestamp') # Set it as the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8306dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kittyoomm\\AppData\\Local\\Temp\\ipykernel_11924\\1961443209.py:5: FutureWarning: 'S' is deprecated and will be removed in a future version, please use 's' instead.\n",
      "  index = pd.date_range(start=start_time, end=end_time, freq='2S')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>time_total</th>\n",
       "      <th>conductivity</th>\n",
       "      <th>Anomaly C</th>\n",
       "      <th>pH</th>\n",
       "      <th>Anomaly P</th>\n",
       "      <th>temperature</th>\n",
       "      <th>Anomaly T</th>\n",
       "      <th>voltage</th>\n",
       "      <th>Anomaly V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-01-01 00:00:00</th>\n",
       "      <td>JUL_22_1</td>\n",
       "      <td>2</td>\n",
       "      <td>56.32</td>\n",
       "      <td>N</td>\n",
       "      <td>4.02</td>\n",
       "      <td>N</td>\n",
       "      <td>49.70</td>\n",
       "      <td>N</td>\n",
       "      <td>3.639</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01 00:00:02</th>\n",
       "      <td>JUL_22_1</td>\n",
       "      <td>4</td>\n",
       "      <td>56.32</td>\n",
       "      <td>N</td>\n",
       "      <td>4.02</td>\n",
       "      <td>N</td>\n",
       "      <td>49.70</td>\n",
       "      <td>N</td>\n",
       "      <td>3.705</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01 00:00:04</th>\n",
       "      <td>JUL_22_1</td>\n",
       "      <td>6</td>\n",
       "      <td>56.17</td>\n",
       "      <td>N</td>\n",
       "      <td>4.02</td>\n",
       "      <td>N</td>\n",
       "      <td>49.71</td>\n",
       "      <td>N</td>\n",
       "      <td>3.702</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01 00:00:06</th>\n",
       "      <td>JUL_22_1</td>\n",
       "      <td>8</td>\n",
       "      <td>56.17</td>\n",
       "      <td>N</td>\n",
       "      <td>4.02</td>\n",
       "      <td>N</td>\n",
       "      <td>49.68</td>\n",
       "      <td>N</td>\n",
       "      <td>3.673</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01 00:00:08</th>\n",
       "      <td>JUL_22_1</td>\n",
       "      <td>10</td>\n",
       "      <td>56.17</td>\n",
       "      <td>N</td>\n",
       "      <td>4.02</td>\n",
       "      <td>N</td>\n",
       "      <td>49.69</td>\n",
       "      <td>N</td>\n",
       "      <td>3.668</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01 04:58:46</th>\n",
       "      <td>JUL_24_3</td>\n",
       "      <td>20318</td>\n",
       "      <td>56.80</td>\n",
       "      <td>N</td>\n",
       "      <td>4.25</td>\n",
       "      <td>N</td>\n",
       "      <td>49.99</td>\n",
       "      <td>N</td>\n",
       "      <td>3.459</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01 04:58:48</th>\n",
       "      <td>JUL_24_3</td>\n",
       "      <td>20320</td>\n",
       "      <td>57.01</td>\n",
       "      <td>C3</td>\n",
       "      <td>4.25</td>\n",
       "      <td>N</td>\n",
       "      <td>49.98</td>\n",
       "      <td>N</td>\n",
       "      <td>3.461</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01 04:58:50</th>\n",
       "      <td>JUL_24_3</td>\n",
       "      <td>20322</td>\n",
       "      <td>56.80</td>\n",
       "      <td>N</td>\n",
       "      <td>4.25</td>\n",
       "      <td>N</td>\n",
       "      <td>49.97</td>\n",
       "      <td>N</td>\n",
       "      <td>3.466</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01 04:58:52</th>\n",
       "      <td>JUL_24_3</td>\n",
       "      <td>20324</td>\n",
       "      <td>56.80</td>\n",
       "      <td>N</td>\n",
       "      <td>4.25</td>\n",
       "      <td>N</td>\n",
       "      <td>49.98</td>\n",
       "      <td>N</td>\n",
       "      <td>3.463</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01 04:58:54</th>\n",
       "      <td>JUL_24_3</td>\n",
       "      <td>20326</td>\n",
       "      <td>57.01</td>\n",
       "      <td>C3</td>\n",
       "      <td>4.25</td>\n",
       "      <td>N</td>\n",
       "      <td>49.98</td>\n",
       "      <td>N</td>\n",
       "      <td>3.464</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8968 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       run_id  time_total  conductivity Anomaly C    pH  \\\n",
       "2025-01-01 00:00:00  JUL_22_1           2         56.32         N  4.02   \n",
       "2025-01-01 00:00:02  JUL_22_1           4         56.32         N  4.02   \n",
       "2025-01-01 00:00:04  JUL_22_1           6         56.17         N  4.02   \n",
       "2025-01-01 00:00:06  JUL_22_1           8         56.17         N  4.02   \n",
       "2025-01-01 00:00:08  JUL_22_1          10         56.17         N  4.02   \n",
       "...                       ...         ...           ...       ...   ...   \n",
       "2025-01-01 04:58:46  JUL_24_3       20318         56.80         N  4.25   \n",
       "2025-01-01 04:58:48  JUL_24_3       20320         57.01        C3  4.25   \n",
       "2025-01-01 04:58:50  JUL_24_3       20322         56.80         N  4.25   \n",
       "2025-01-01 04:58:52  JUL_24_3       20324         56.80         N  4.25   \n",
       "2025-01-01 04:58:54  JUL_24_3       20326         57.01        C3  4.25   \n",
       "\n",
       "                    Anomaly P  temperature Anomaly T voltage Anomaly V  \n",
       "2025-01-01 00:00:00         N        49.70         N   3.639         N  \n",
       "2025-01-01 00:00:02         N        49.70         N   3.705         N  \n",
       "2025-01-01 00:00:04         N        49.71         N   3.702         N  \n",
       "2025-01-01 00:00:06         N        49.68         N   3.673         N  \n",
       "2025-01-01 00:00:08         N        49.69         N   3.668         N  \n",
       "...                       ...          ...       ...     ...       ...  \n",
       "2025-01-01 04:58:46         N        49.99         N   3.459            \n",
       "2025-01-01 04:58:48         N        49.98         N   3.461            \n",
       "2025-01-01 04:58:50         N        49.97         N   3.466            \n",
       "2025-01-01 04:58:52         N        49.98         N   3.463            \n",
       "2025-01-01 04:58:54         N        49.98         N   3.464            \n",
       "\n",
       "[8968 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 1. Create a dummy DataFrame for demonstration (skip this if you have your data) ---\n",
    "# Your original data has 600 points collected every 2 seconds\n",
    "start_time = pd.to_datetime('2025-01-01 00:00:00')\n",
    "end_time = start_time + pd.Timedelta(seconds=(len(filtered_df)-1) * 2) # Total duration is 1198 seconds, or 19 min 58 sec\n",
    "index = pd.date_range(start=start_time, end=end_time, freq='2S')\n",
    "filtered_df = filtered_df.set_index(index) # Set it as the index\n",
    "filtered_df\n",
    "# -------------------------------------------------------------------------------------\n",
    "resampled_df = filtered_df.resample('2s').first()\n",
    "resampled_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
